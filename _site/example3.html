<!DOCTYPE html>
<html lang="en-US">

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="/assets/css/style.css?v=">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Some Class Examples</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Some Class Examples" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/example3.html" />
<meta property="og:url" content="http://localhost:4000/example3.html" />
<meta property="og:site_name" content="Some Class Examples" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Some Class Examples" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Some Class Examples","url":"http://localhost:4000/example3.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          

          <h1 id="project_title">Some Class Examples</h1>
          <h2 id="project_tagline"></h2>
          <a href="http://localhost:4000//index.html">Return to Home</a>

          
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1 id="more-nba">More NBA</h1>

<h2 id="introduction">Introduction:</h2>

<p>I was really excited to work on this project and with this data set. I was very excited to find this data set on the hugging face website. It was a dream come true for an NBA fan to be presented with this much statistical data in one place. I really wanted to focus on the question of what statistical part of the NBA game most impacts a team’s probability to win games. The hot topic statistic right now is three-point shooting percentage and attempts. So, as I progress through my data, I want to see if that is correct or if there is a different metric that is better suited at predicting wins.</p>

<h2 id="methods">Methods:</h2>
<p>Through feature engineering, I improved my model’s performance by applying KNN Clusters, PCA and t-SNE for dimensionality reduction, and anomaly detection. KNN clustering allowed me to group similar data points and create a new feature representing cluster assignments, which helped the model capture non-linear relationships and added contextual information. PCA reduced the dataset’s dimensionality, eliminating redundant or noisy features, improving generalization, and speeding up training. Meanwhile, t-SNE provided insights into non-linear relationships and revealed intrinsic patterns, aiding feature selection and debugging. Anomaly detection identified and removed outliers, ensuring the model trained on clean, representative data and avoided skew from extreme values. Together, these methods enhanced the model’s accuracy, reduced overfitting, and improved robustness and interpretability, leading to better overall performance.</p>

<h2 id="models-used">Models Used:</h2>

<p>The first model that I used was a logistic regression model, but due to over/underfitting or some other error, it gave me an accuracy of 1. So, I decided not to use this model.</p>

<p>The Extremely Randomized Trees classifier is an ensemble learning method that builds multiple decision trees, like Random Forests, but introduces additional randomness by selecting split thresholds randomly for each feature. This reduces overfitting and increases robustness. Key hyperparameters explored likely included the number of trees (n_estimators), maximum depth of trees (max_depth), and minimum samples per split (min_samples_split). The model achieved a test accuracy of 91.62%, showing strong performance and suggesting effective handling of feature interactions and variability.</p>

<p>Histogram Gradient Boosting is a variant of gradient boosting that discretizes continuous features into bins, improving efficiency for large datasets. It works iteratively to reduce errors by combining weak learners, typically decision trees. Key hyperparameters likely tuned were the learning rate, number of bins, and maximum number of iterations (n_estimators). This model achieved the highest accuracy of 95.33%, indicating excellent generalization and strong learning from the dataset.</p>

<p>Gradient Boosting is an iterative ensemble technique that builds models sequentially, minimizing errors in each step by optimizing a differentiable loss function. Key hyperparameters explored probably included the learning rate, number of boosting stages (n_estimators), and the maximum depth of trees (max_depth). This model achieved a test accuracy of 93.95%, reflecting effective learning and generalization with strong performance.</p>

<p>AdaBoost combines multiple weak learners, such as decision trees, by focusing on misclassified instances in each iteration. Key hyperparameters explored likely included the number of estimators (n_estimators) and the learning rate. This model achieved a test accuracy of 94.11%, demonstrating its strength in reducing bias while maintaining high generalization performance.</p>

<p>The SVC is a linear or kernel-based classification method that aims to find the optimal hyperplane to separate data points. Key hyperparameters explored were likely the kernel type (linear, RBF, etc.), regularization parameter (C), and kernel coefficient (gamma). Despite its effectiveness in many tasks, the model performed poorly here, with a test accuracy of 54.67%, likely due to non-linear data patterns or suboptimal hyperparameters for the dataset.</p>

<p>The KNN algorithm classifies data points based on the majority label of their nearest neighbors in the feature space. Key hyperparameters explored likely included the number of neighbors (k) and the distance metric (Euclidean, Manhattan, etc.). The model achieved an accuracy of 84%, reflecting moderate performance, likely due to its sensitivity to noise and high-dimensional data.</p>

<p>Random Forest is an ensemble of decision trees that combines predictions from multiple trees, reducing overfitting and improving generalization. Key hyperparameters explored were probably the number of trees (n_estimators), maximum tree depth (max_depth), and minimum samples per split (min_samples_split). The model achieved a strong accuracy of 91%, highlighting its robustness and ability to handle diverse datasets.</p>

<p>Decision Trees partition the feature space into regions based on decision rules, but they are prone to overfitting without pruning. Key hyperparameters explored might have included the maximum depth (max_depth), minimum samples per split, and splitting criteria (Gini vs. entropy). The model achieved an accuracy of 82%, indicating decent performance but limited by potential overfitting or lack of ensemble learning.</p>

<p>The deep learning model I used is a feedforward neural network built with TensorFlow’s Keras Sequential API. It consists of an input layer with 32 features, followed by two dense hidden layers with 500 and 200 neurons, respectively, each using the ReLU activation function and L2 regularization to reduce overfitting. Both layers use the He Normal initialization to ensure efficient training. The output layer has a single neuron with a sigmoid activation function, appropriate for binary classification. The model is compiled with categorical cross-entropy as the loss function, the Adam optimizer for efficient parameter updates, and accuracy as the evaluation metric. However, I am concerned about the high-test loss (3343.58) despite achieving a test accuracy of approximately 51.2%. This significant discrepancy between the loss and accuracy could indicate issues such as improper model architecture, label misalignment, or poor feature scaling. It raises concerns about the model’s robustness and its ability to generalize effectively, necessitating further investigation and tuning to improve performance.</p>

<h2 id="overall-thoughts-on-model-selection">Overall Thoughts on model selection:</h2>
<p>As I tested different models to fine tune my model that I wanted to use for my predictions, I saw that the best model was the Histogram Gradient Boosting with a 95% accuracy score. I did notice that overall, the random forest or tree-based models were consistently out preforming the other models. This made sense in terms of my data because it is easy to make decision trees regarding what is a good or bad game based on averages for the team. So, it would make sense to me that those models would perform better overall.</p>

<p>I also noticed that the ensemble models, specifically Extremely Randomized Trees, Histogram Gradient Boosting, Gradient Boosting, AdaBoost, and Random Forest all preformed better overall compared to the non-ensemble models.</p>

<p>Overall, the most important metric for me when it came to which model I used was the accuracy of the model. I wanted to make a model that performed at the highest level to make the best predictions of wins or losses for each game. I valued accuracy over different metrics such as running time or levels of intensity for the model. Some models did not make the cut because of over/underfitting issues like the logistic regression model. Other models were not considered because of the complexity of setting up the model and tuning the hyperparameters.</p>

<h2 id="detailed-discussion-on-best-model">Detailed Discussion on Best Model:</h2>

<p>The Histogram Gradient Boosting model, which achieved the highest test accuracy of 95.33%, was my best model. Hyperparameter tuning played a critical role in optimizing its performance. Key hyperparameters likely explored included the number of bins for discretizing continuous features, the number of boosting iterations (n_estimators), the learning rate, the maximum depth of individual trees (max_depth), and the minimum number of samples required to split a node (min_samples_split). The learning rate, in particular, balances model precision and convergence speed, while the number of iterations ensures sufficient optimization without overfitting. Regularization parameters, such as max leaf nodes and minimum samples, could have been adjusted to prevent overfitting and improve generalization.</p>

<p>In terms of performance metrics, the model’s test accuracy of 95.33% indicates exceptional generalization capability, outperforming other models in the task. Test accuracy measures the proportion of correct predictions on unseen data, which validates the model’s ability to handle both training and test distributions effectively. The low computational cost and high accuracy make Histogram Gradient Boosting an excellent choice.</p>

<p>The part of the data analysis that I was most excited about was the SHAP values. I loved the use of the bee swarm plot pictured below to help show which NBA statistics are most influential to predicting a win or a loss in an NBA game. It was interesting to see that FG percentage and attempts were the most influential statistics over three-point shooting like I predicted.</p>

<p>The main thing that I wish I could have gotten to work was KNN clustering. I am not sure if I had too many data points or what was the issue, I could not get the clusters to separate and show me any trends or patterns. The anomaly detection was interesting on the other hand. That is something that I will want to go back to and take a closer look at to see if there are any clear trends and patterns in the anomalies that I can learn from to help improve my model.</p>

<h2 id="conclusion">Conclusion:</h2>

<p>The choice to use tree-based models as my main form of predicting was a clear choice and helped make my model solid and dependable. I learned a lot through testing different models and finding which ones worked the best. Choosing a tree-based model will help keep the model ridged and avoid overfitting which is a problem that I think other models continually ran into from my data set.</p>

<p>My conclusion for this report is that the best way to predict if a team won or lost a basketball game is to look at their field goal percentage and their opponents field goal percentage. If they are able to stop their opponents from making shots and find ways to take high percentage shots and make them, they are significantly more likely to win the game.</p>

<p>Going forward, I would love to go back and figure out what was going on with my cluster analysis. If I was able to get that working better I would have been able to get my overall model working better as well. I would consider trimming down my data set as well, maybe only using one year instead of all four. This would allow me to narrow down on any trends before applying to the whole data set. As I continue to learn new techniques and models, I will continue to apply them to the sport that I love and continue to allow statistics and machine learning to help me understand the real world better. I am so grateful for this opportunity to experience this real-life problem solving and see how cool machine learning can be!</p>


      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        
      </footer>
    </div>
  </body>
</html>
